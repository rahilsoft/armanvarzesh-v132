

## Tiles (Prisma) â€” Production Notes
- Run migrations: `pnpm prisma generate && pnpm prisma migrate dev --name init_tiles`
- GraphQL:
  - Query: `tiles(page)` returns current tiles with fields incl. variant/weight.
  - Mutations:
    - `upsertTile(input:{ page, type, variant?, weight?, data(JSON), actorId })` (roles: admin/editor)
    - `publishTile(tileId, actorId)` (roles: admin)
- RBAC:
  - Configure `AUTH_JWKS_URL` or `ADMIN_JWT_PUBLIC_KEY` (PEM string) and optionally `AUTH_ISSUER`/`AUTH_AUDIENCE`.
  - Roles expected in JWT: `roles` array or space-separated `scope`.
- Uploads:
  - `getSignedUpload(contentType, ext?)` uses S3 presigned URL (expires 15 min). Configure S3 envs.


## Preview Drafts
- Query `tiles(page, includeDraft)` returns DRAFT + PUBLISHED when `includeDraft=true`.
- Secure preview by checking a header (e.g., `X-Preview-Token`) in a custom guard/middleware against `PREVIEW_TOKEN` env.


## Preview Security
- Set `PREVIEW_TOKEN` and send `X-Preview-Token` header to allow `includeDraft=true` in tiles query.
- Alternatively, authenticated users with proper roles (via RolesGuard) can access drafts.


## Signed Preview Links
- Set `PREVIEW_SIGNING_KEY` (random secret).
- Generate token: `generatePreviewToken(page:"home", ttlSec:900)` (roles: admin/editor).
- Frontend passes token via `?preview=<token>` â†’ header `X-Preview-Token` sent automatically (see vitrin-site).


## Media Pipeline (sharp)
- Query: `makeImageVariants(url:String!, maxWidth?:Int)` â†’ `{ blurDataURL, variants[] }`
- Ø¯Ø± Ø­Ø§Ù„Øª DEV ÙÙ‚Ø· blurDataURL ØªÙˆÙ„ÛŒØ¯ Ù…ÛŒâ€ŒØ´ÙˆØ¯. Ø¨Ø±Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ Ùˆ Ø¢Ù¾Ù„ÙˆØ¯ ÙˆØ±Ú˜Ù†â€ŒÙ‡Ø§ Ø¨Ù‡ S3 Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒÙ… Ø¯Ø± Ú¯Ø§Ù… Ø¨Ø¹Ø¯ S3 Put Ø±Ø§ Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†ÛŒÙ….


## Image Variants (AVIF/WebP + blur)
- Query: `makeImageVariantsFull(url, widths?, bucketPrefix?)` â†’ `{ files[{url,format,width}], blurDataURL }`
- Ø§Ú¯Ø± `S3_BUCKET` Ùˆ Ø§Ø¹ØªØ¨Ø§Ø±Ù†Ø§Ù…Ù‡â€ŒÙ‡Ø§ Ø³Øª Ø´ÙˆÙ†Ø¯ØŒ Ù†Ø³Ø®Ù‡â€ŒÙ‡Ø§ Ø¯Ø± S3 Ø¢Ù¾Ù„ÙˆØ¯ Ùˆ URL Ø¹Ù…ÙˆÙ…ÛŒ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.
- Ø¨Ø±Ø§ÛŒ CDNØŒ `PUBLIC_MEDIA_BASE` Ø±Ø§ Ø¨Ù‡ Ù…Ø¨Ø¯Ø£ CDN Ø³Øª Ú©Ù†ÛŒØ¯.

## Observability (OpenTelemetry)
- `src/tracing.ts` Ø¨Ø§ OTLP HTTP Exporter. ENV: `OTEL_EXPORTER_OTLP_ENDPOINT`.


## DB Hardening
- Added `logicalId` to `Tile` + indexes: `@@index([page, logicalId, variant, state])`, `@@index([updatedAt])`.
- Audit trail: `PublishAudit` model with actions (UPSERT/PUBLISH/ARCHIVE).

## Rate Limiting & Cache
- Simple token-bucket `RateGuard` (in-memory) available for GraphQL (attach as needed).
- CacheModule + CacheInterceptor applied on read queries (TTL ~30s).
- CORS with allowlist via `CORS_ORIGINS` env; Helmet enabled.

## Health
- `GET /healthz` & `GET /ready`


## Audit GraphQL
- Query: `auditLogs(tileId?, page?, limit?, cursor?)` â†’ Ù„Ø§Ú¯â€ŒÙ‡Ø§ÛŒ PublishAudit Ø¨Ø§ snapshot JSON Ø¨Ø±Ø§ÛŒ Diff Ø³Ù…Øª Ú©Ù„Ø§ÛŒÙ†Øª.

## S3 Cache-Control
- Ù†Ø³Ø®Ù‡â€ŒÙ‡Ø§ Ø¨Ø§ `CacheControl: public, max-age=31536000, immutable` Ø¢Ù¾Ù„ÙˆØ¯ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯ (Ù‚Ø§Ø¨Ù„â€ŒØªØ®ØµÛŒØµ Ø¨Ø§ fork).


## Feature Flags (GraphQL)
- Query: `featureFlags` â†’ Ù„ÛŒØ³Øª ÙÙ„Ú¯â€ŒÙ‡Ø§ÛŒ Ø§Ø¯ØºØ§Ù…â€ŒØ´Ø¯Ù‡ Ø§Ø² ENV `FEATURE_FLAGS_JSON` Ùˆ DB.
- Mutation: `setFeatureFlag(key,value,actorId?,description?)` (roles: admin/editor).



## Plan Builder v2 â€” GraphQL
- **Exercises**: `exercises(search, muscle, equipment, cursor, limit, ownerId)`; `upsertExercise(input)`, `reviewExercise(id,status)`
- **Upload**: `uploadVoice(data, ext)` â†’ Ø°Ø®ÛŒØ±Ù‡Ù” ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ùˆ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù† URL
- **Plans**: `plan(id)`, `plans(cursor,limit,search)`, `upsertPlan(input)`, `publishPlan(id)`, `duplicatePlan(id)`
- **Assign**: `assignPlan(planId, clientId, startDate, sessionsPerWeek, restDays, durationDays)` â†’ Ø§ÛŒØ¬Ø§Ø¯ Ø¬Ù„Ø³Ø§Øª Ø¨Ø±Ù†Ø§Ù…Ù‡
- Prisma models: `ExerciseVideo` (Ø¨Ø§ ÙˆØ¶Ø¹ÛŒØª ØªØ£ÛŒÛŒØ¯)ØŒ `Plan/PlanDay/PlanBlock/PlanBlockItem/PlanSet`, `PlanAssignment/PlanSession`


### S3 Upload (Ø§Ø®ØªÛŒØ§Ø±ÛŒØŒ ØªÙˆØµÛŒÙ‡â€ŒØ´Ø¯Ù‡)
- Ù…ØªØºÛŒÙ‘Ø±Ù‡Ø§: `AWS_REGION`, `S3_BUCKET`, `AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY`
- Mutation: `requestUploadUrl(kind, ext)` â†’ `{ uploadUrl, fileUrl }` (Ø¯Ø± ÙÛŒÙ„Ø¯ `url` Ø¨Ù‡â€ŒØµÙˆØ±Øª JSON Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø¯)
- Ø¨Ø±Ø§ÛŒ ÙˆÙÛŒØ³ Ù‡Ù…Ú†Ù†Ø§Ù† `uploadVoice(base64)` Ø¨Ù‡â€ŒØ¹Ù†ÙˆØ§Ù† fallback Ù…Ø­Ù„ÛŒ ÙØ¹Ø§Ù„ Ø§Ø³Øª.


### Sessions & Reassign
- `sessionsByClient(clientId, from, to)` â†’ Ù„ÛŒØ³Øª Ø¬Ù„Ø³Ø§Øª Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø²Ù‡Ù” ØªØ§Ø±ÛŒØ®ÛŒ
- `reassignPlanDates(assignmentId, startDate, sessionsPerWeek, restDays[], durationDays)` â†’ Ø¨Ø§Ø²ØªÙˆÙ„ÛŒØ¯ Ø¬Ù„Ø³Ø§Øª


### Media Processing
- `processExerciseMedia(id)` â†’ Ù…Ø­Ø§Ø³Ø¨Ù‡Ù” `durationSec` Ø¨Ø§ ffprobe Ùˆ Ø³Ø§Ø®Øª `thumbnailUrl` (Ù„ÙˆÚ©Ø§Ù„ ÛŒØ§ S3).
- Ù…Ø¯Ù„ `ExerciseVideo` Ø§Ù„Ø§Ù† `thumbnailUrl` Ùˆ `durationSec` Ø¯Ø§Ø±Ø¯.


### Media Worker (BullMQ)
- Env: `REDIS_URL` Ø¨Ø±Ø§ÛŒ ÙØ¹Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ ØµÙ. Ø§Ú¯Ø± Ø®Ø§Ù„ÛŒ Ø¨Ø§Ø´Ø¯ØŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ù‡â€ŒØµÙˆØ±Øª inline Ø§Ø¬Ø±Ø§ Ù…ÛŒâ€ŒØ´ÙˆØ¯.
- `enqueueMediaProcessing(exerciseId)` Ø¯Ø± upsertExercise ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ Ù…ÛŒâ€ŒØ´ÙˆØ¯.
- `processExerciseMediaHandler(id)` Ù…Ù†Ø·Ù‚ FFmpeg/ffprobe Ø±Ø§ Ø§Ù†Ø¬Ø§Ù… Ù…ÛŒâ€ŒØ¯Ù‡Ø¯.


### AnatomyConfig
- Ù…Ø¯Ù„: `AnatomyConfig` Ø¨Ø§ ÙÛŒÙ„Ø¯Ù‡Ø§ÛŒ `gender`, `modelUrl`, `meshMap(JSON)`ØŒ `active`.
- Query: `anatomyConfig(gender)`Ø› Mutation: `upsertAnatomyConfig(input)`.

### Multipart Upload (S3)
- `createMultipartUpload(kind, ext)` â†’ `{ uploadId, key }`
- `signUploadPart(key, uploadId, partNumber)` â†’ URL Ø¨Ø±Ø§ÛŒ Ù‡Ø± part
- `completeMultipartUpload(key, uploadId, parts(JSON))` â†’ `{ url }`


### Sessions â€” Execution & Logs
- Ù…Ø¯Ù„â€ŒÙ‡Ø§: `PlanSession.status/completedAt`, `PlanSet.targetWeight/targetRPE`, `PlanSetLog`.
- Query: `sessionDetail(id)` â€” Ø¬Ø²Ø¦ÛŒØ§Øª Ø¬Ù„Ø³Ù‡ + Ø¨Ù„ÙˆÚ©â€ŒÙ‡Ø§/Ø¢ÛŒØªÙ…â€ŒÙ‡Ø§/Ø³Øªâ€ŒÙ‡Ø§.
- Mutations: `startSession`, `completeSession`, `logSet(sessionId, planSetId, reps, weight?, rpe?, note?)`.
- Auto-progression: `autoProgressAssignment(assignmentId, mode?)` â€” Ø³Ø§Ø¯Ù‡: ÙˆØ²Ù† +2.5 Ú©ÛŒÙ„Ùˆ ÛŒØ§ Ø§ÙØ²Ø§ÛŒØ´ ØªÚ©Ø±Ø§Ø± ØªØ§ Ø³Ù‚Ù 12.



### Exercise Search & Popularity
- Query: `searchExercises(input)` Ø¨Ø§ ÙÛŒÙ„ØªØ±Ù‡Ø§ÛŒ search/muscles/equipment/sports/level/kind/duration Ùˆ sortBy (RECENT|POPULAR|DURATION)
- Mutations: `exerciseView(id)`, `exerciseLike(id, delta?)`
- Ù…Ø¯Ù„ `ExerciseVideo` Ø´Ø§Ù…Ù„ `viewCount/likeCount`

### Plan Ops â€” Reorder/Duplicate
- `reorderPlanBlocks(dayId, orderedIds[])`, `reorderPlanItems(blockId, orderedIds[])`
- `duplicateBlock(blockId)`, `duplicateDay(dayId)`


### Security (Ø³Ø¨Ú©)
- Ù‡Ø¯Ø±Ù‡Ø§ÛŒ `x-role` Ùˆ `x-user-id` Ø¯Ø± GraphQL Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ù†Ù‚Ø´/Ú©Ø§Ø±Ø¨Ø±. Ø¨Ø§ `SKIP_AUTH=1` Ø§Ø² Ú¯Ø§Ø±Ø¯ Ø¹Ø¨ÙˆØ± Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
- Mutation `approveExercise(id, status?)` ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ `admin` Ù…Ø¬Ø§Ø² Ø§Ø³Øª.


### Advanced Plan APIs
- `updateBlockMeta(blockId, section?, type?, rounds?, restBetweenItemsSec?)`
- `applyProtocol(blockId, protocol, paramsJSON?)` â€” Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ø®ÙˆØ¯Ú©Ø§Ø± Ø³Øªâ€ŒÙ‡Ø§/Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ Ø¨Ø±Ø§ÛŒ 5x5, GVT, EMOM, HIIT
- `validatePlan(planId)` â€” Ø¨Ø±Ø±Ø³ÛŒ Ù†Ø§Ø³Ø§Ø²Ú¯Ø§Ø±ÛŒâ€ŒÙ‡Ø§ (Superset/Triset/Circuit/EMOM/HIIT)
- `simulateSession(sessionId)` â€” Ø¨Ø±Ø¢ÙˆØ±Ø¯ Ø²Ù…Ø§Ù† Ø§Ø¬Ø±Ø§ÛŒ Ø¬Ù„Ø³Ù‡ (Ø«Ø§Ù†ÛŒÙ‡) Ø¯Ø± Ø³Ø·Ø­ Ø¨Ù„ÙˆÚ© Ùˆ Ú©Ù„


### Session Notes & Audio
- Model: `PlanSessionNote(sessionId, role, text?, audioUrl?, authorId?, createdAt)`
- Queries: `sessionNotes(sessionId)`
- Mutations: `upsertSessionNote(input)`
- Upload: `requestUploadUrl(kind, ext)` â†’ JSON `{ uploadUrl, fileUrl }` (S3 presigned ÛŒØ§ fallback)

### Scheduling (Month)
- `generatePlanSchedule(assignmentId, startDate, sessionsPerWeek, restDaysJSON?)` â†’ Ø³Ø§Ø®Øª Ø®ÙˆØ¯Ú©Ø§Ø± Ø¬Ù„Ø³Ø§Øª ~Û´ Ù‡ÙØªÙ‡ Ø¨Ø§ Ø§Ø­ØªØ±Ø§Ù… Ø¨Ù‡ Ø±ÙˆØ²Ù‡Ø§ÛŒ Ø§Ø³ØªØ±Ø§Ø­Øª.


### Analytics (GraphQL)
- `userAdherence(clientId, from, to)` â€” Ù†Ø±Ø® ØªÚ©Ù…ÛŒÙ„ Ø¬Ù„Ø³Ø§Øª
- `topExercises(limit?)` â€” Ù…Ø­Ø¨ÙˆØ¨â€ŒØªØ±ÛŒÙ† ØªÙ…Ø±ÛŒÙ†â€ŒÙ‡Ø§ (â¤/ğŸ‘)
- `trainingLoadByWeek(clientId, weeks?)` â€” Ø¨Ø§Ø± ØªÙ…Ø±ÛŒÙ†ÛŒ (Î£ reps Ã— weight) Ø¨Ù‡ ØªÙÚ©ÛŒÚ© Ù‡ÙØªÙ‡

### Security (Dev)
- Ù‡Ø¯Ø±Ù‡Ø§ÛŒ `x-role` / `x-user-id` Ø¨Ø§ `SKIP_AUTH=1` Ø¨Ø±Ø§ÛŒ ØªÙˆØ³Ø¹Ù‡Ø› Ø¯Ø± Ù¾Ø±ÙˆØ¯Ø§Ú©Ø´Ù† Ø§Ø² Gateway/JWT Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯.



| Script | Command |
|---|---|
| `build` | `tsc -p tsconfig.build.json` |
| `clean` | `rimraf dist || true` |
| `coverage` | `jest --coverage --passWithNoTests` |
| `dev` | `ts-node src/main.ts` |
| `format` | `prettier --write .` |
| `format:check` | `prettier -c . || echo "no prettier"` |
| `lint` | `pnpm -w exec eslint . --ext .ts,.tsx || echo "no eslint"` |
| `prepare` | `husky install || true` |
| `prisma:db:push` | `prisma db push --schema prisma/schema.prisma` |
| `prisma:generate` | `prisma generate --schema prisma/schema.prisma` |
| `prisma:migrate` | `prisma migrate deploy` |
| `prisma:migrate:deploy` | `prisma migrate deploy --schema prisma/schema.prisma` |
| `prisma:migrate:dev` | `prisma migrate dev --name init --schema prisma/schema.prisma` |
| `prisma:studio` | `prisma studio` |
| `sbom` | `npx @cyclonedx/cyclonedx-npm --ignore-npm-errors --json --output-file sbom.json` |
| `start` | `node dist/main.js` |
| `start:dev` | `nodemon --watch 'src/**/*.ts' --exec 'ts-node' src/main.ts || nest start --watch` |
| `start:prod` | `node dist/main.js` |
| `test` | `jest --passWithNoTests || vitest run || echo "no tests"` |
| `test:cov` | `jest --coverage --runInBand` |
| `test:e2e` | `jest --config ./test/jest-e2e.json` |
| `typecheck` | `tsc -p tsconfig.build.json --noEmit` |

## Environment
Use `.env` or inherit from repo root. Required variables (examples):
- `DATABASE_URL` â€” Postgres connection string
- `REDIS_URL` â€” Redis connection string
- `JWT_SECRET` â€” JWT signing secret
- `CORS_ORIGIN` â€” Comma-separated origins (e.g. https://app.example.com,https://admin.example.com)

## Development
- Lint: `pnpm run lint`
- Typecheck: `pnpm run typecheck`
- Tests: `pnpm run test` (coverage: `pnpm run coverage`)

## Deployment
- Containerized via Dockerfile (if present). Healthcheck: `GET /health`, Metrics: `GET /metrics` (Prometheus).
- See repo Release workflow for build & publish (GHCR).

## Security
- No secrets in repo. Use env variables or secret manager. Helmet/CORS configured in Nest/Next.

---
_This README was scaffolded in Phase 8 (Docs) to standardize documentation across the monorepo._
